{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T16:57:45.448403Z",
     "start_time": "2025-04-17T16:57:44.712875Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "\n",
    "sz = 8  # Size of the input image\n",
    "layers = [sz * sz, 8, 8, 10]\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(layers[0], layers[1])\n",
    "        self.fc2 = nn.Linear(layers[1], layers[2])\n",
    "        self.fc3 = nn.Linear(layers[2], layers[3])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = f.relu(self.fc1(x))\n",
    "        x = f.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def predict(ffnn_model, image):\n",
    "    with torch.no_grad():\n",
    "        logits = ffnn_model(image)\n",
    "        predicted = torch.argmax(logits, dim=1)\n",
    "        return predicted"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T16:57:47.591734Z",
     "start_time": "2025-04-17T16:57:45.526596Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(),  # Convert RGB to 1-channel\n",
    "    transforms.Resize((sz, sz)),  # Resize to 8x8\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_data = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_data = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T16:57:59.713112Z",
     "start_time": "2025-04-17T16:57:47.599882Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = Classifier()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(5):\n",
    "    print(f\"Epoch {epoch + 1}\")\n",
    "    for images, labels in train_loader:\n",
    "        output = model(images)\n",
    "        loss = loss_fn(output, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T16:58:00.067192Z",
     "start_time": "2025-04-17T16:57:59.724361Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get one test image and label\n",
    "test_img, test_label = test_data[4]\n",
    "plt.imshow(test_img.squeeze(), cmap='gray')\n",
    "plt.title(f\"True Label: {test_label}\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Model prediction\n",
    "model.eval()\n",
    "test_img_input = test_img.unsqueeze(0)  # Add batch dimension\n",
    "pred = predict(model, test_img_input)\n",
    "print(f\"Predicted Label: {pred.item()}\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: 5\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T16:58:00.104618Z",
     "start_time": "2025-04-17T16:58:00.078504Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from z3 import *\n",
    "from z3 import If\n",
    "\n",
    "\n",
    "def encode_nn_with_smt(input_image, model_weights, perturbation_bound, timeout=10000):\n",
    "    def R(x):\n",
    "        return RealVal(x)\n",
    "\n",
    "    # Define input variables with perturbation constraints\n",
    "    input_vars = [Real(f'x_{i}') for i in range(layers[0])]\n",
    "    perturbed_vars = [Real(f'x_perturbed_{i}') for i in range(layers[0])]\n",
    "    constraints = []\n",
    "\n",
    "    print(\"Defining constraints for input variables\")\n",
    "    for i in range(layers[0]):\n",
    "        constraints.append(input_vars[i] == R(input_image[i]))\n",
    "        constraints.append(perturbed_vars[i] >= 0)\n",
    "        constraints.append(perturbed_vars[i] <= 1)  # Assuming normalized input\n",
    "\n",
    "    # L2-norm perturbation constraint\n",
    "    diff_squares = [(perturbed_vars[i] - input_vars[i]) ** 2\n",
    "                    for i in range(layers[0])]\n",
    "    constraints.append(Sum(diff_squares) <= R(perturbation_bound ** 2))\n",
    "\n",
    "    print(\"Added input variable constraints\")\n",
    "    # Encode the first layer: y1 = ReLU(W1 * x + b1)\n",
    "    W1, b1 = model_weights['fc1']\n",
    "    y1 = [Real(f'y1_{i}') for i in range(layers[1])]\n",
    "    for i in range(layers[1]):\n",
    "        linear_expr = Sum([R(round(W1[i][j], 5)) * perturbed_vars[j] for j in range(layers[0])]) + R(round(b1[i], 5))\n",
    "        constraints.append(y1[i] == If(linear_expr > 0, linear_expr, 0))\n",
    "\n",
    "    print(\"Added first layer constraints\")\n",
    "    # Encode the second layer: y2 = ReLU(W2 * y1 + b2)\n",
    "    W2, b2 = model_weights['fc2']\n",
    "    y2 = [Real(f'y2_{i}') for i in range(layers[2])]\n",
    "    for i in range(layers[2]):\n",
    "        linear_expr = Sum([R(round(W2[i][j], 5)) * y1[j] for j in range(layers[1])]) + R(round(b2[i], 5))\n",
    "        constraints.append(y2[i] == If(linear_expr > 0, linear_expr, 0))\n",
    "\n",
    "    print(\"Added second layer constraints\")\n",
    "    # Encode the third layer: y3 = W3 * y2 + b3\n",
    "    W3, b3 = model_weights['fc3']\n",
    "    y3 = [Real(f'y3_{i}') for i in range(layers[3])]\n",
    "    for i in range(layers[3]):\n",
    "        linear_expr = Sum([R(round(W3[i][j], 5)) * y2[j] for j in range(layers[2])]) + R(round(b3[i], 5))\n",
    "        constraints.append(y3[i] == linear_expr)\n",
    "\n",
    "    print(\"Added third layer constraints\")\n",
    "    # Encode ArgMax: Ensure the predicted class remains the same\n",
    "    pred_class = model_weights['predicted_class']\n",
    "    for i in range(10):\n",
    "        if i != pred_class:\n",
    "            constraints.append(y3[pred_class] >= y3[i])\n",
    "\n",
    "    print(\"Added all constraints\")\n",
    "\n",
    "    with open(\"nn_encoding.smt2\", \"w\") as smt_file:\n",
    "        solver = Solver()\n",
    "        solver.add(constraints)\n",
    "        smt_file.write(solver.to_smt2())\n",
    "    print(\"SMT encoding written to nn_encoding.smt2\")\n",
    "\n",
    "    # Print size of SMT problem\n",
    "    print(f\"Number of constraints: {len(constraints)}\")\n",
    "    print(f\"Number of variables: {len(input_vars) + len(perturbed_vars) + len(y1) + len(y2)} ({sz}x{sz} input)\")\n",
    "\n",
    "    # Solve the constraints\n",
    "    solver = Solver()\n",
    "    solver.set(\"timeout\", timeout)\n",
    "    solver.add(constraints)\n",
    "    print(\"Solving...\")\n",
    "    result = solver.check()\n",
    "    print(f\"Result: {result}\")\n",
    "    if result == sat:\n",
    "        print(\"SAT: Perturbation within bounds\")\n",
    "    elif result == unsat:\n",
    "        print(\"UNSAT: Perturbation exceeds bounds\")\n",
    "    else:\n",
    "        print(\"UNKNOWN: Solver could not determine satisfiability\")\n"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T16:58:09.300980Z",
     "start_time": "2025-04-17T16:58:00.118740Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Loading CIFAR10 test dataset\")\n",
    "test_loader = DataLoader(test_data, batch_size=1, shuffle=True)\n",
    "test_image, test_label = next(iter(test_loader))  # Get one test image and label\n",
    "test_image = test_image.view(-1, sz * sz)  # Flatten the image\n",
    "\n",
    "print(\"Extracting model weights and biases\")\n",
    "model.eval()\n",
    "fc1_weights = model.fc1.weight.detach().tolist()\n",
    "fc1_biases = model.fc1.bias.detach().tolist()\n",
    "fc2_weights = model.fc2.weight.detach().tolist()\n",
    "fc2_biases = model.fc2.bias.detach().tolist()\n",
    "fc3_weights = model.fc3.weight.detach().tolist()\n",
    "fc3_biases = model.fc3.bias.detach().tolist()\n",
    "\n",
    "predicted_class = predict(model, test_image).item()\n",
    "print(f\"Predicted class for the test image: {predicted_class}\")\n",
    "\n",
    "model_weights = {\n",
    "    'fc1': (fc1_weights, fc1_biases),\n",
    "    'fc2': (fc2_weights, fc2_biases),\n",
    "    'fc3': (fc3_weights, fc3_biases),\n",
    "    'predicted_class': predicted_class\n",
    "}\n",
    "\n",
    "input_image = test_image.squeeze().tolist()  # Convert to a list\n",
    "perturbation_bound = 0.00001  # Example perturbation bound\n",
    "\n",
    "print(\"Encoding the neural network with SMT solver\")\n",
    "encode_nn_with_smt(input_image, model_weights, perturbation_bound, 100000)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CIFAR10 test dataset\n",
      "Extracting model weights and biases\n",
      "Predicted class for the test image: 5\n",
      "Encoding the neural network with SMT solver\n",
      "Defining constraints for input variables\n",
      "Added input variable constraints\n",
      "Added first layer constraints\n",
      "Added second layer constraints\n",
      "Added third layer constraints\n",
      "Added all constraints\n",
      "SMT encoding written to nn_encoding.smt2\n",
      "Number of constraints: 228\n",
      "Number of variables: 144 (8x8 input)\n",
      "Solving...\n",
      "Result: sat\n",
      "SAT: Perturbation within bounds\n"
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
